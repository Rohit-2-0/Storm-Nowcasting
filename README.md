# â›ˆï¸ Storm Nowcasting with LSTM, Random Forest, and XGBoost

This project builds predictive models to forecast storm occurrences at two time horizons: **1 hour** and **3 hours** in advance. The goal is to support early warning systems using a combination of deep learning (LSTM) and traditional machine learning models (Random Forest, XGBoost).

---

## ğŸ“ Files

- `Storm_Nowcasting_updated_ipynb_...ipynb` â€“ Jupyter Notebook containing full data preprocessing, model training, and evaluation pipeline.
- `train.csv` â€“ Dataset with storm records, used for supervised learning.

---

## ğŸ“Š Features Used

The following features are extracted from storm data:

- **lat** â€“ Latitude  
- **lon** â€“ Longitude  
- **intensity** â€“ Storm intensity metric  
- **size** â€“ Storm size  
- **distance** â€“ Distance from target zone  

---

## ğŸ§ª Target Variables

Two separate binary classification targets:

- `Storm_NosyBe_1h` â€“ Predicts whether a storm will occur 1 hour later  
- `Storm_NosyBe_3h` â€“ Predicts whether a storm will occur 3 hours later  

---

## âš™ï¸ Technologies & Libraries

- `pandas`, `numpy` â€“ Data handling  
- `scikit-learn` â€“ Preprocessing, train-test split, evaluation  
- `tensorflow.keras` â€“ Deep learning (LSTM)  
- `xgboost` â€“ Gradient Boosted Decision Trees  

---

## ğŸ§  Model Architectures

### ğŸ§¬ LSTM Neural Network

Custom LSTM model built with Keras:

```python
model = Sequential()
model.add(LSTM(64, return_sequences=True, activation='tanh', input_shape=input_shape))
model.add(LSTM(32, return_sequences=False, activation='tanh'))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
```
ğŸŒ² Random Forest Classifier

Used as a traditional baseline model:

from sklearn.ensemble import RandomForestClassifier

```
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_flat, y_train)
```
âš¡ XGBoost Classifier

A powerful gradient boosting model for tabular classification:
```
from xgboost import XGBClassifier

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train_flat, y_train)
```
ğŸ“ˆ Evaluation Metrics

    Accuracy â€“ For overall performance comparison

    ROC AUC Score â€“ To assess the model's ability to separate classes

    ROC Curves â€“ Plotted for LSTM, Random Forest, and XGBoost

    Probability outputs â€“ From predict_proba or sigmoid activation

    (Optional) Confusion Matrix, Precision, Recall for additional diagnostics
